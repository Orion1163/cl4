import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Load the dataset from local CSV
df = pd.read_csv('iris_dataset.csv')

# Separate features and target
X = df.iloc[:, :-1]  # All columns except the last (features)
y = df.iloc[:, -1]   # Last column (target)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Initialize and train the logistic regression model
logreg = LogisticRegression(max_iter=200)
logreg.fit(X_train_scaled, y_train)

# Predictions
y_pred_train = logreg.predict(X_train_scaled)
y_pred_test = logreg.predict(X_test_scaled)

# Model evaluation
print("Training Accuracy:", accuracy_score(y_train, y_pred_train))
print("Testing Accuracy:", accuracy_score(y_test, y_pred_test))

# Additional evaluation metrics
print("Classification Report on Test Data:")
print(classification_report(y_test, y_pred_test))



Practical 3: Perform the data classification algorithm using any Classification algorithm
Theory
Classification is a supervised machine learning technique used to predict the categorical class labels of new instances, based on past observations. It involves training a model on a labeled dataset, which means that each training example is paired with an output label. Once trained, the model can classify new data into one of the predefined classes.

The purpose of classification is to identify which category an object belongs to based on a training dataset containing observations whose category membership is known. Common examples include spam detection in emails, disease prediction in healthcare, and sentiment analysis in text.

Types of Classification Algorithms:
Decision Tree – A tree-like model used for decision-making. It splits the dataset into branches to arrive at a decision.

K-Nearest Neighbors (KNN) – Classifies a data point based on how its neighbors are classified.

Support Vector Machine (SVM) – Finds the optimal boundary that best separates classes in the feature space.

Naive Bayes – Based on Bayes’ Theorem and assumes feature independence.

Logistic Regression – A statistical model that uses a logistic function to model binary dependent variables.

Steps in Classification:
Data Collection – Gather labeled data.

Data Preprocessing – Clean the data, handle missing values, normalize/standardize if required.

Splitting the Dataset – Usually into training and testing sets (e.g., 80/20 split).

Model Selection – Choose a classification algorithm.

Model Training – Use the training data to teach the model.

Model Evaluation – Assess the accuracy, precision, recall, and F1-score using test data.

Prediction – Apply the model to unseen data for classification.

Advantages of Classification Algorithms:
Easy to interpret (especially decision trees).

High performance with enough labeled data.

Applicable to various domains like finance, healthcare, and marketing.

Applications of Classification:
Email spam detection

Credit card fraud detection

Medical diagnosis

Image and speech recognition

